name: 'Crawl Actions '
#触发
on:
  watch:
    types: [started]
  schedule:
    - cron: '0 14 * * *'
      
jobs:
  Crawl:
    runs-on: ubuntu-latest
    steps:

    - name: Checkout tools repo
      uses: actions/checkout@v2
      with:
        repository: cdh1991/solutions
        token: ${{ secrets.TOKEN }}
        path: ./
      
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas requests BeautifulSoup4
    - name: crawl list to csv
      run: |
        python crawl.py
    - name: Pushes test file
      uses: dmnemec/copy_file_to_another_repo_action@v1.0.4
      env:
        API_TOKEN_GITHUB: ${{ secrets.TOKEN }}
      with:
        source_file: 'solutions'
        destination_repo: 'cdh1991/solutions'
        destination_branch: 'solutions' 
        destination_folder: './'
        user_email: 'example@email.com'
        user_name: 'cdh1991'
        commit_message: 'A custom message for the commit'
