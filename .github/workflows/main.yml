name: 'Crawl Actions '
#触发
on:
  watch:
    types: [started]
  schedule:
    - cron: '0 14 * * *'
      
jobs:
  Crawl:
    runs-on: ubuntu-latest
    steps:

    - name: Checkout tools repo
      uses: actions/checkout@v2
      with:
        repository: cdh1991/solutions
        token: ${{ secrets.TOKEN }}
        path: ./
      
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas requests BeautifulSoup4
    - name: crawl list to csv
      run: |
        python crawl.py
    - name: Pushes to another repository
      uses: cpina/github-action-push-to-another-repository@master
      env:
        API_TOKEN_GITHUB: ${{ secrets.TOKEN }}
      with:
        source-directory: './'
        destination-github-username: 'cdh1991'
        destination-repository-name: 'solutions'
        user-email: 858600803@qq.com
